# -*- coding: utf-8 -*-
"""Test_Fish.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PfufeIhbj1xeyrDzzMDaDlV7CT06rZ13


from google.colab import drive
drive.mount("/content/gdrive")
!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/MyDrive/Colab Notebooks/AI&DC-I/Datasets"
!ls
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

#Importamos los datos de entrada
data = pd.read_csv('Fish.csv')

#Matriz de correlacion
cor_data = data[['Weight',  'Length1',  'Length2',  'Length3',  'Height', 'Width']]
cor_d = cor_data.corr()
cor_d.style.background_gradient (cmap = 'coolwarm')

# Función de evaulación de desempeño del modelo de regresión lineal
def evalMLR(X_train, X_test, y_train, y_test):
  # Declaración de modelo de regresión lineal
  mlr = LinearRegression()
  # Ajuste de nuestro modelo
  mlr.fit(X_train, y_train)
  #Predicciónes del modelo
  y_hat_train = mlr.predict(X_train)
  y_hat_test = mlr.predict(X_test)
  # Validación
  sc_train = r2_score(y_train, y_hat_train)
  sc_test = r2_score(y_test, y_hat_test)
  mse = mean_squared_error(y_test, y_hat_test)
  print("R2_Train = "+ "{:.6}".format(sc_train*100)+ "%\tR2_Test = "+
        "{:.6}".format(sc_test*100)+"%\tECM = "+ "{:.6}".format(mse)+"\n")

# Creamos nuestras caracteristicas nuevas para nuestro modelo
data['L123']= (data['Length1'] * data['Length2'] * data['Length3'])**(1/3)
data['WidthXL123'] = data['L123']*data['Width']
y = data[['Weight']]
data.head()

#Matriz de correlacion con las nuevas caracteristicas
cor_data = data[['Weight',  'Length1',  'Length2',  'Length3',  'Height', 'Width','L123',	'WidthXL123']]
cor_d = cor_data.corr()
cor_d.style.background_gradient (cmap = 'coolwarm')

# Caracteristicas para los distintos modelos
x1 = data[['Length1','Length2','Length3','Width','L123','WidthXL123']]
x2 = data[['Length1','Length2','Length3','Width']]
x3 = data[['Width','L123','WidthXL123']]
x4 = data[['Width','L123']]
x5 = data[['Length1','Length2','Length3','WidthXL123']]
x6 = data[['Length1','Length2','Length3','L123']]

chars_x = [x1,x2, x3, x4, x5, x6]
rands = [1, 4, 21, 105, 837]

for i in range(len(rands)):
  # Se corren para 5 muestras para cada modelo
  print("\t"*3+"MUESTRA",i+1)
  for j in range(len(chars_x)):
    # Separamos un conjunto de datos para entrenar y otro para probar
    X_train, X_test, y_train, y_test = train_test_split(chars_x[j], y, random_state=rands[i])
    # Llamamos a nuestra función para el modelo
    print("Modelo",j+1)
    evalMLR(X_train, X_test, y_train, y_test)
